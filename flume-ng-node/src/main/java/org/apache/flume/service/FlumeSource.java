/**
 * Autogenerated by Thrift Compiler (0.11.0)
 *
 * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
 *  @generated
 */
package org.apache.flume.service;

@SuppressWarnings({"cast", "rawtypes", "serial", "unchecked", "unused"})
@javax.annotation.Generated(value = "Autogenerated by Thrift Compiler (0.11.0)", date = "2018-08-10")
public class FlumeSource implements org.apache.thrift.TBase<FlumeSource, FlumeSource._Fields>, java.io.Serializable, Cloneable, Comparable<FlumeSource> {
  private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("FlumeSource");

  private static final org.apache.thrift.protocol.TField SOURCE_TYPE_FIELD_DESC = new org.apache.thrift.protocol.TField("sourceType", org.apache.thrift.protocol.TType.I32, (short)1);
  private static final org.apache.thrift.protocol.TField HTTP_SOURCE_FIELD_DESC = new org.apache.thrift.protocol.TField("httpSource", org.apache.thrift.protocol.TType.STRUCT, (short)2);
  private static final org.apache.thrift.protocol.TField KAFKA_SOURCE_FIELD_DESC = new org.apache.thrift.protocol.TField("kafkaSource", org.apache.thrift.protocol.TType.STRUCT, (short)3);
  private static final org.apache.thrift.protocol.TField HDFS_SOURCE_FIELD_DESC = new org.apache.thrift.protocol.TField("hdfsSource", org.apache.thrift.protocol.TType.STRUCT, (short)4);
  private static final org.apache.thrift.protocol.TField DB_SOURCE_FIELD_DESC = new org.apache.thrift.protocol.TField("dbSource", org.apache.thrift.protocol.TType.STRUCT, (short)5);
  private static final org.apache.thrift.protocol.TField INTERCEPTOR_LIST_FIELD_DESC = new org.apache.thrift.protocol.TField("interceptorList", org.apache.thrift.protocol.TType.LIST, (short)6);

  private static final org.apache.thrift.scheme.SchemeFactory STANDARD_SCHEME_FACTORY = new FlumeSourceStandardSchemeFactory();
  private static final org.apache.thrift.scheme.SchemeFactory TUPLE_SCHEME_FACTORY = new FlumeSourceTupleSchemeFactory();

  /**
   * 
   * @see SourceType
   */
  public SourceType sourceType; // required
  public HttpSource httpSource; // optional
  public KafkaSource kafkaSource; // optional
  public HDFSSource hdfsSource; // optional
  public DBSource dbSource; // optional
  public java.util.List<Interceptor> interceptorList; // optional

  /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
  public enum _Fields implements org.apache.thrift.TFieldIdEnum {
    /**
     * 
     * @see SourceType
     */
    SOURCE_TYPE((short)1, "sourceType"),
    HTTP_SOURCE((short)2, "httpSource"),
    KAFKA_SOURCE((short)3, "kafkaSource"),
    HDFS_SOURCE((short)4, "hdfsSource"),
    DB_SOURCE((short)5, "dbSource"),
    INTERCEPTOR_LIST((short)6, "interceptorList");

    private static final java.util.Map<java.lang.String, _Fields> byName = new java.util.HashMap<java.lang.String, _Fields>();

    static {
      for (_Fields field : java.util.EnumSet.allOf(_Fields.class)) {
        byName.put(field.getFieldName(), field);
      }
    }

    /**
     * Find the _Fields constant that matches fieldId, or null if its not found.
     */
    public static _Fields findByThriftId(int fieldId) {
      switch(fieldId) {
        case 1: // SOURCE_TYPE
          return SOURCE_TYPE;
        case 2: // HTTP_SOURCE
          return HTTP_SOURCE;
        case 3: // KAFKA_SOURCE
          return KAFKA_SOURCE;
        case 4: // HDFS_SOURCE
          return HDFS_SOURCE;
        case 5: // DB_SOURCE
          return DB_SOURCE;
        case 6: // INTERCEPTOR_LIST
          return INTERCEPTOR_LIST;
        default:
          return null;
      }
    }

    /**
     * Find the _Fields constant that matches fieldId, throwing an exception
     * if it is not found.
     */
    public static _Fields findByThriftIdOrThrow(int fieldId) {
      _Fields fields = findByThriftId(fieldId);
      if (fields == null) throw new java.lang.IllegalArgumentException("Field " + fieldId + " doesn't exist!");
      return fields;
    }

    /**
     * Find the _Fields constant that matches name, or null if its not found.
     */
    public static _Fields findByName(java.lang.String name) {
      return byName.get(name);
    }

    private final short _thriftId;
    private final java.lang.String _fieldName;

    _Fields(short thriftId, java.lang.String fieldName) {
      _thriftId = thriftId;
      _fieldName = fieldName;
    }

    public short getThriftFieldId() {
      return _thriftId;
    }

    public java.lang.String getFieldName() {
      return _fieldName;
    }
  }

  // isset id assignments
  private static final _Fields optionals[] = {_Fields.HTTP_SOURCE,_Fields.KAFKA_SOURCE,_Fields.HDFS_SOURCE,_Fields.DB_SOURCE,_Fields.INTERCEPTOR_LIST};
  public static final java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
  static {
    java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new java.util.EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
    tmpMap.put(_Fields.SOURCE_TYPE, new org.apache.thrift.meta_data.FieldMetaData("sourceType", org.apache.thrift.TFieldRequirementType.REQUIRED, 
        new org.apache.thrift.meta_data.EnumMetaData(org.apache.thrift.protocol.TType.ENUM, SourceType.class)));
    tmpMap.put(_Fields.HTTP_SOURCE, new org.apache.thrift.meta_data.FieldMetaData("httpSource", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
        new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, HttpSource.class)));
    tmpMap.put(_Fields.KAFKA_SOURCE, new org.apache.thrift.meta_data.FieldMetaData("kafkaSource", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
        new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, KafkaSource.class)));
    tmpMap.put(_Fields.HDFS_SOURCE, new org.apache.thrift.meta_data.FieldMetaData("hdfsSource", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
        new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, HDFSSource.class)));
    tmpMap.put(_Fields.DB_SOURCE, new org.apache.thrift.meta_data.FieldMetaData("dbSource", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
        new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, DBSource.class)));
    tmpMap.put(_Fields.INTERCEPTOR_LIST, new org.apache.thrift.meta_data.FieldMetaData("interceptorList", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
        new org.apache.thrift.meta_data.ListMetaData(org.apache.thrift.protocol.TType.LIST, 
            new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRUCT            , "Interceptor"))));
    metaDataMap = java.util.Collections.unmodifiableMap(tmpMap);
    org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(FlumeSource.class, metaDataMap);
  }

  public FlumeSource() {
  }

  public FlumeSource(
    SourceType sourceType)
  {
    this();
    this.sourceType = sourceType;
  }

  /**
   * Performs a deep copy on <i>other</i>.
   */
  public FlumeSource(FlumeSource other) {
    if (other.isSetSourceType()) {
      this.sourceType = other.sourceType;
    }
    if (other.isSetHttpSource()) {
      this.httpSource = new HttpSource(other.httpSource);
    }
    if (other.isSetKafkaSource()) {
      this.kafkaSource = new KafkaSource(other.kafkaSource);
    }
    if (other.isSetHdfsSource()) {
      this.hdfsSource = new HDFSSource(other.hdfsSource);
    }
    if (other.isSetDbSource()) {
      this.dbSource = new DBSource(other.dbSource);
    }
    if (other.isSetInterceptorList()) {
      java.util.List<Interceptor> __this__interceptorList = new java.util.ArrayList<Interceptor>(other.interceptorList.size());
      for (Interceptor other_element : other.interceptorList) {
        __this__interceptorList.add(new Interceptor(other_element));
      }
      this.interceptorList = __this__interceptorList;
    }
  }

  public FlumeSource deepCopy() {
    return new FlumeSource(this);
  }

  @Override
  public void clear() {
    this.sourceType = null;
    this.httpSource = null;
    this.kafkaSource = null;
    this.hdfsSource = null;
    this.dbSource = null;
    this.interceptorList = null;
  }

  /**
   * 
   * @see SourceType
   */
  public SourceType getSourceType() {
    return this.sourceType;
  }

  /**
   * 
   * @see SourceType
   */
  public FlumeSource setSourceType(SourceType sourceType) {
    this.sourceType = sourceType;
    return this;
  }

  public void unsetSourceType() {
    this.sourceType = null;
  }

  /** Returns true if field sourceType is set (has been assigned a value) and false otherwise */
  public boolean isSetSourceType() {
    return this.sourceType != null;
  }

  public void setSourceTypeIsSet(boolean value) {
    if (!value) {
      this.sourceType = null;
    }
  }

  public HttpSource getHttpSource() {
    return this.httpSource;
  }

  public FlumeSource setHttpSource(HttpSource httpSource) {
    this.httpSource = httpSource;
    return this;
  }

  public void unsetHttpSource() {
    this.httpSource = null;
  }

  /** Returns true if field httpSource is set (has been assigned a value) and false otherwise */
  public boolean isSetHttpSource() {
    return this.httpSource != null;
  }

  public void setHttpSourceIsSet(boolean value) {
    if (!value) {
      this.httpSource = null;
    }
  }

  public KafkaSource getKafkaSource() {
    return this.kafkaSource;
  }

  public FlumeSource setKafkaSource(KafkaSource kafkaSource) {
    this.kafkaSource = kafkaSource;
    return this;
  }

  public void unsetKafkaSource() {
    this.kafkaSource = null;
  }

  /** Returns true if field kafkaSource is set (has been assigned a value) and false otherwise */
  public boolean isSetKafkaSource() {
    return this.kafkaSource != null;
  }

  public void setKafkaSourceIsSet(boolean value) {
    if (!value) {
      this.kafkaSource = null;
    }
  }

  public HDFSSource getHdfsSource() {
    return this.hdfsSource;
  }

  public FlumeSource setHdfsSource(HDFSSource hdfsSource) {
    this.hdfsSource = hdfsSource;
    return this;
  }

  public void unsetHdfsSource() {
    this.hdfsSource = null;
  }

  /** Returns true if field hdfsSource is set (has been assigned a value) and false otherwise */
  public boolean isSetHdfsSource() {
    return this.hdfsSource != null;
  }

  public void setHdfsSourceIsSet(boolean value) {
    if (!value) {
      this.hdfsSource = null;
    }
  }

  public DBSource getDbSource() {
    return this.dbSource;
  }

  public FlumeSource setDbSource(DBSource dbSource) {
    this.dbSource = dbSource;
    return this;
  }

  public void unsetDbSource() {
    this.dbSource = null;
  }

  /** Returns true if field dbSource is set (has been assigned a value) and false otherwise */
  public boolean isSetDbSource() {
    return this.dbSource != null;
  }

  public void setDbSourceIsSet(boolean value) {
    if (!value) {
      this.dbSource = null;
    }
  }

  public int getInterceptorListSize() {
    return (this.interceptorList == null) ? 0 : this.interceptorList.size();
  }

  public java.util.Iterator<Interceptor> getInterceptorListIterator() {
    return (this.interceptorList == null) ? null : this.interceptorList.iterator();
  }

  public void addToInterceptorList(Interceptor elem) {
    if (this.interceptorList == null) {
      this.interceptorList = new java.util.ArrayList<Interceptor>();
    }
    this.interceptorList.add(elem);
  }

  public java.util.List<Interceptor> getInterceptorList() {
    return this.interceptorList;
  }

  public FlumeSource setInterceptorList(java.util.List<Interceptor> interceptorList) {
    this.interceptorList = interceptorList;
    return this;
  }

  public void unsetInterceptorList() {
    this.interceptorList = null;
  }

  /** Returns true if field interceptorList is set (has been assigned a value) and false otherwise */
  public boolean isSetInterceptorList() {
    return this.interceptorList != null;
  }

  public void setInterceptorListIsSet(boolean value) {
    if (!value) {
      this.interceptorList = null;
    }
  }

  public void setFieldValue(_Fields field, java.lang.Object value) {
    switch (field) {
    case SOURCE_TYPE:
      if (value == null) {
        unsetSourceType();
      } else {
        setSourceType((SourceType)value);
      }
      break;

    case HTTP_SOURCE:
      if (value == null) {
        unsetHttpSource();
      } else {
        setHttpSource((HttpSource)value);
      }
      break;

    case KAFKA_SOURCE:
      if (value == null) {
        unsetKafkaSource();
      } else {
        setKafkaSource((KafkaSource)value);
      }
      break;

    case HDFS_SOURCE:
      if (value == null) {
        unsetHdfsSource();
      } else {
        setHdfsSource((HDFSSource)value);
      }
      break;

    case DB_SOURCE:
      if (value == null) {
        unsetDbSource();
      } else {
        setDbSource((DBSource)value);
      }
      break;

    case INTERCEPTOR_LIST:
      if (value == null) {
        unsetInterceptorList();
      } else {
        setInterceptorList((java.util.List<Interceptor>)value);
      }
      break;

    }
  }

  public java.lang.Object getFieldValue(_Fields field) {
    switch (field) {
    case SOURCE_TYPE:
      return getSourceType();

    case HTTP_SOURCE:
      return getHttpSource();

    case KAFKA_SOURCE:
      return getKafkaSource();

    case HDFS_SOURCE:
      return getHdfsSource();

    case DB_SOURCE:
      return getDbSource();

    case INTERCEPTOR_LIST:
      return getInterceptorList();

    }
    throw new java.lang.IllegalStateException();
  }

  /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
  public boolean isSet(_Fields field) {
    if (field == null) {
      throw new java.lang.IllegalArgumentException();
    }

    switch (field) {
    case SOURCE_TYPE:
      return isSetSourceType();
    case HTTP_SOURCE:
      return isSetHttpSource();
    case KAFKA_SOURCE:
      return isSetKafkaSource();
    case HDFS_SOURCE:
      return isSetHdfsSource();
    case DB_SOURCE:
      return isSetDbSource();
    case INTERCEPTOR_LIST:
      return isSetInterceptorList();
    }
    throw new java.lang.IllegalStateException();
  }

  @Override
  public boolean equals(java.lang.Object that) {
    if (that == null)
      return false;
    if (that instanceof FlumeSource)
      return this.equals((FlumeSource)that);
    return false;
  }

  public boolean equals(FlumeSource that) {
    if (that == null)
      return false;
    if (this == that)
      return true;

    boolean this_present_sourceType = true && this.isSetSourceType();
    boolean that_present_sourceType = true && that.isSetSourceType();
    if (this_present_sourceType || that_present_sourceType) {
      if (!(this_present_sourceType && that_present_sourceType))
        return false;
      if (!this.sourceType.equals(that.sourceType))
        return false;
    }

    boolean this_present_httpSource = true && this.isSetHttpSource();
    boolean that_present_httpSource = true && that.isSetHttpSource();
    if (this_present_httpSource || that_present_httpSource) {
      if (!(this_present_httpSource && that_present_httpSource))
        return false;
      if (!this.httpSource.equals(that.httpSource))
        return false;
    }

    boolean this_present_kafkaSource = true && this.isSetKafkaSource();
    boolean that_present_kafkaSource = true && that.isSetKafkaSource();
    if (this_present_kafkaSource || that_present_kafkaSource) {
      if (!(this_present_kafkaSource && that_present_kafkaSource))
        return false;
      if (!this.kafkaSource.equals(that.kafkaSource))
        return false;
    }

    boolean this_present_hdfsSource = true && this.isSetHdfsSource();
    boolean that_present_hdfsSource = true && that.isSetHdfsSource();
    if (this_present_hdfsSource || that_present_hdfsSource) {
      if (!(this_present_hdfsSource && that_present_hdfsSource))
        return false;
      if (!this.hdfsSource.equals(that.hdfsSource))
        return false;
    }

    boolean this_present_dbSource = true && this.isSetDbSource();
    boolean that_present_dbSource = true && that.isSetDbSource();
    if (this_present_dbSource || that_present_dbSource) {
      if (!(this_present_dbSource && that_present_dbSource))
        return false;
      if (!this.dbSource.equals(that.dbSource))
        return false;
    }

    boolean this_present_interceptorList = true && this.isSetInterceptorList();
    boolean that_present_interceptorList = true && that.isSetInterceptorList();
    if (this_present_interceptorList || that_present_interceptorList) {
      if (!(this_present_interceptorList && that_present_interceptorList))
        return false;
      if (!this.interceptorList.equals(that.interceptorList))
        return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    int hashCode = 1;

    hashCode = hashCode * 8191 + ((isSetSourceType()) ? 131071 : 524287);
    if (isSetSourceType())
      hashCode = hashCode * 8191 + sourceType.getValue();

    hashCode = hashCode * 8191 + ((isSetHttpSource()) ? 131071 : 524287);
    if (isSetHttpSource())
      hashCode = hashCode * 8191 + httpSource.hashCode();

    hashCode = hashCode * 8191 + ((isSetKafkaSource()) ? 131071 : 524287);
    if (isSetKafkaSource())
      hashCode = hashCode * 8191 + kafkaSource.hashCode();

    hashCode = hashCode * 8191 + ((isSetHdfsSource()) ? 131071 : 524287);
    if (isSetHdfsSource())
      hashCode = hashCode * 8191 + hdfsSource.hashCode();

    hashCode = hashCode * 8191 + ((isSetDbSource()) ? 131071 : 524287);
    if (isSetDbSource())
      hashCode = hashCode * 8191 + dbSource.hashCode();

    hashCode = hashCode * 8191 + ((isSetInterceptorList()) ? 131071 : 524287);
    if (isSetInterceptorList())
      hashCode = hashCode * 8191 + interceptorList.hashCode();

    return hashCode;
  }

  @Override
  public int compareTo(FlumeSource other) {
    if (!getClass().equals(other.getClass())) {
      return getClass().getName().compareTo(other.getClass().getName());
    }

    int lastComparison = 0;

    lastComparison = java.lang.Boolean.valueOf(isSetSourceType()).compareTo(other.isSetSourceType());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetSourceType()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.sourceType, other.sourceType);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = java.lang.Boolean.valueOf(isSetHttpSource()).compareTo(other.isSetHttpSource());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetHttpSource()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.httpSource, other.httpSource);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = java.lang.Boolean.valueOf(isSetKafkaSource()).compareTo(other.isSetKafkaSource());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetKafkaSource()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.kafkaSource, other.kafkaSource);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = java.lang.Boolean.valueOf(isSetHdfsSource()).compareTo(other.isSetHdfsSource());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetHdfsSource()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.hdfsSource, other.hdfsSource);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = java.lang.Boolean.valueOf(isSetDbSource()).compareTo(other.isSetDbSource());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetDbSource()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.dbSource, other.dbSource);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = java.lang.Boolean.valueOf(isSetInterceptorList()).compareTo(other.isSetInterceptorList());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetInterceptorList()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.interceptorList, other.interceptorList);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    return 0;
  }

  public _Fields fieldForId(int fieldId) {
    return _Fields.findByThriftId(fieldId);
  }

  public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
    scheme(iprot).read(iprot, this);
  }

  public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
    scheme(oprot).write(oprot, this);
  }

  @Override
  public java.lang.String toString() {
    java.lang.StringBuilder sb = new java.lang.StringBuilder("FlumeSource(");
    boolean first = true;

    sb.append("sourceType:");
    if (this.sourceType == null) {
      sb.append("null");
    } else {
      sb.append(this.sourceType);
    }
    first = false;
    if (isSetHttpSource()) {
      if (!first) sb.append(", ");
      sb.append("httpSource:");
      if (this.httpSource == null) {
        sb.append("null");
      } else {
        sb.append(this.httpSource);
      }
      first = false;
    }
    if (isSetKafkaSource()) {
      if (!first) sb.append(", ");
      sb.append("kafkaSource:");
      if (this.kafkaSource == null) {
        sb.append("null");
      } else {
        sb.append(this.kafkaSource);
      }
      first = false;
    }
    if (isSetHdfsSource()) {
      if (!first) sb.append(", ");
      sb.append("hdfsSource:");
      if (this.hdfsSource == null) {
        sb.append("null");
      } else {
        sb.append(this.hdfsSource);
      }
      first = false;
    }
    if (isSetDbSource()) {
      if (!first) sb.append(", ");
      sb.append("dbSource:");
      if (this.dbSource == null) {
        sb.append("null");
      } else {
        sb.append(this.dbSource);
      }
      first = false;
    }
    if (isSetInterceptorList()) {
      if (!first) sb.append(", ");
      sb.append("interceptorList:");
      if (this.interceptorList == null) {
        sb.append("null");
      } else {
        sb.append(this.interceptorList);
      }
      first = false;
    }
    sb.append(")");
    return sb.toString();
  }

  public void validate() throws org.apache.thrift.TException {
    // check for required fields
    if (sourceType == null) {
      throw new org.apache.thrift.protocol.TProtocolException("Required field 'sourceType' was not present! Struct: " + toString());
    }
    // check for sub-struct validity
    if (httpSource != null) {
      httpSource.validate();
    }
    if (kafkaSource != null) {
      kafkaSource.validate();
    }
    if (hdfsSource != null) {
      hdfsSource.validate();
    }
    if (dbSource != null) {
      dbSource.validate();
    }
  }

  private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
    try {
      write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
    } catch (org.apache.thrift.TException te) {
      throw new java.io.IOException(te);
    }
  }

  private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, java.lang.ClassNotFoundException {
    try {
      read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
    } catch (org.apache.thrift.TException te) {
      throw new java.io.IOException(te);
    }
  }

  private static class FlumeSourceStandardSchemeFactory implements org.apache.thrift.scheme.SchemeFactory {
    public FlumeSourceStandardScheme getScheme() {
      return new FlumeSourceStandardScheme();
    }
  }

  private static class FlumeSourceStandardScheme extends org.apache.thrift.scheme.StandardScheme<FlumeSource> {

    public void read(org.apache.thrift.protocol.TProtocol iprot, FlumeSource struct) throws org.apache.thrift.TException {
      org.apache.thrift.protocol.TField schemeField;
      iprot.readStructBegin();
      while (true)
      {
        schemeField = iprot.readFieldBegin();
        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
          break;
        }
        switch (schemeField.id) {
          case 1: // SOURCE_TYPE
            if (schemeField.type == org.apache.thrift.protocol.TType.I32) {
              struct.sourceType = org.apache.flume.service.SourceType.findByValue(iprot.readI32());
              struct.setSourceTypeIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 2: // HTTP_SOURCE
            if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
              struct.httpSource = new HttpSource();
              struct.httpSource.read(iprot);
              struct.setHttpSourceIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 3: // KAFKA_SOURCE
            if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
              struct.kafkaSource = new KafkaSource();
              struct.kafkaSource.read(iprot);
              struct.setKafkaSourceIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 4: // HDFS_SOURCE
            if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
              struct.hdfsSource = new HDFSSource();
              struct.hdfsSource.read(iprot);
              struct.setHdfsSourceIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 5: // DB_SOURCE
            if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
              struct.dbSource = new DBSource();
              struct.dbSource.read(iprot);
              struct.setDbSourceIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 6: // INTERCEPTOR_LIST
            if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
              {
                org.apache.thrift.protocol.TList _list0 = iprot.readListBegin();
                struct.interceptorList = new java.util.ArrayList<Interceptor>(_list0.size);
                Interceptor _elem1;
                for (int _i2 = 0; _i2 < _list0.size; ++_i2)
                {
                  _elem1 = new Interceptor();
                  _elem1.read(iprot);
                  struct.interceptorList.add(_elem1);
                }
                iprot.readListEnd();
              }
              struct.setInterceptorListIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          default:
            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
        }
        iprot.readFieldEnd();
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      struct.validate();
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot, FlumeSource struct) throws org.apache.thrift.TException {
      struct.validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (struct.sourceType != null) {
        oprot.writeFieldBegin(SOURCE_TYPE_FIELD_DESC);
        oprot.writeI32(struct.sourceType.getValue());
        oprot.writeFieldEnd();
      }
      if (struct.httpSource != null) {
        if (struct.isSetHttpSource()) {
          oprot.writeFieldBegin(HTTP_SOURCE_FIELD_DESC);
          struct.httpSource.write(oprot);
          oprot.writeFieldEnd();
        }
      }
      if (struct.kafkaSource != null) {
        if (struct.isSetKafkaSource()) {
          oprot.writeFieldBegin(KAFKA_SOURCE_FIELD_DESC);
          struct.kafkaSource.write(oprot);
          oprot.writeFieldEnd();
        }
      }
      if (struct.hdfsSource != null) {
        if (struct.isSetHdfsSource()) {
          oprot.writeFieldBegin(HDFS_SOURCE_FIELD_DESC);
          struct.hdfsSource.write(oprot);
          oprot.writeFieldEnd();
        }
      }
      if (struct.dbSource != null) {
        if (struct.isSetDbSource()) {
          oprot.writeFieldBegin(DB_SOURCE_FIELD_DESC);
          struct.dbSource.write(oprot);
          oprot.writeFieldEnd();
        }
      }
      if (struct.interceptorList != null) {
        if (struct.isSetInterceptorList()) {
          oprot.writeFieldBegin(INTERCEPTOR_LIST_FIELD_DESC);
          {
            oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, struct.interceptorList.size()));
            for (Interceptor _iter3 : struct.interceptorList)
            {
              _iter3.write(oprot);
            }
            oprot.writeListEnd();
          }
          oprot.writeFieldEnd();
        }
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

  }

  private static class FlumeSourceTupleSchemeFactory implements org.apache.thrift.scheme.SchemeFactory {
    public FlumeSourceTupleScheme getScheme() {
      return new FlumeSourceTupleScheme();
    }
  }

  private static class FlumeSourceTupleScheme extends org.apache.thrift.scheme.TupleScheme<FlumeSource> {

    @Override
    public void write(org.apache.thrift.protocol.TProtocol prot, FlumeSource struct) throws org.apache.thrift.TException {
      org.apache.thrift.protocol.TTupleProtocol oprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
      oprot.writeI32(struct.sourceType.getValue());
      java.util.BitSet optionals = new java.util.BitSet();
      if (struct.isSetHttpSource()) {
        optionals.set(0);
      }
      if (struct.isSetKafkaSource()) {
        optionals.set(1);
      }
      if (struct.isSetHdfsSource()) {
        optionals.set(2);
      }
      if (struct.isSetDbSource()) {
        optionals.set(3);
      }
      if (struct.isSetInterceptorList()) {
        optionals.set(4);
      }
      oprot.writeBitSet(optionals, 5);
      if (struct.isSetHttpSource()) {
        struct.httpSource.write(oprot);
      }
      if (struct.isSetKafkaSource()) {
        struct.kafkaSource.write(oprot);
      }
      if (struct.isSetHdfsSource()) {
        struct.hdfsSource.write(oprot);
      }
      if (struct.isSetDbSource()) {
        struct.dbSource.write(oprot);
      }
      if (struct.isSetInterceptorList()) {
        {
          oprot.writeI32(struct.interceptorList.size());
          for (Interceptor _iter4 : struct.interceptorList)
          {
            _iter4.write(oprot);
          }
        }
      }
    }

    @Override
    public void read(org.apache.thrift.protocol.TProtocol prot, FlumeSource struct) throws org.apache.thrift.TException {
      org.apache.thrift.protocol.TTupleProtocol iprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
      struct.sourceType = org.apache.flume.service.SourceType.findByValue(iprot.readI32());
      struct.setSourceTypeIsSet(true);
      java.util.BitSet incoming = iprot.readBitSet(5);
      if (incoming.get(0)) {
        struct.httpSource = new HttpSource();
        struct.httpSource.read(iprot);
        struct.setHttpSourceIsSet(true);
      }
      if (incoming.get(1)) {
        struct.kafkaSource = new KafkaSource();
        struct.kafkaSource.read(iprot);
        struct.setKafkaSourceIsSet(true);
      }
      if (incoming.get(2)) {
        struct.hdfsSource = new HDFSSource();
        struct.hdfsSource.read(iprot);
        struct.setHdfsSourceIsSet(true);
      }
      if (incoming.get(3)) {
        struct.dbSource = new DBSource();
        struct.dbSource.read(iprot);
        struct.setDbSourceIsSet(true);
      }
      if (incoming.get(4)) {
        {
          org.apache.thrift.protocol.TList _list5 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
          struct.interceptorList = new java.util.ArrayList<Interceptor>(_list5.size);
          Interceptor _elem6;
          for (int _i7 = 0; _i7 < _list5.size; ++_i7)
          {
            _elem6 = new Interceptor();
            _elem6.read(iprot);
            struct.interceptorList.add(_elem6);
          }
        }
        struct.setInterceptorListIsSet(true);
      }
    }
  }

  private static <S extends org.apache.thrift.scheme.IScheme> S scheme(org.apache.thrift.protocol.TProtocol proto) {
    return (org.apache.thrift.scheme.StandardScheme.class.equals(proto.getScheme()) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY).getScheme();
  }
}

